{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Excel to DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of DataFrames from each Excel file provided by ODA\n",
    "files = {'licenses':'License','locations':'Location','violations':'Violation','inspections':'Contact','addresses':'Address','classifications':'LicenseClassification'}\n",
    "# Change this based on where you are keeping latest version of data\n",
    "path = 'BFS FOIA Request Excel Files/'\n",
    "\n",
    "dfs = {}\n",
    "for dfname in files:\n",
    "    try:\n",
    "        df = pd.ExcelFile(path + files[dfname] + '.xlsx')\n",
    "    except:\n",
    "        print \"Failed to fetch Excel file.\"\n",
    "    df = df.parse(\"Sheet1\",na_values='')\n",
    "    dfs.update({dfname:df})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify unique license type for each license from classifications table\n",
    "license_types_from_classifications = dfs['classifications'].groupby(['_fkLicenseID','LicenseType']).ModifiedBy.count().reset_index()\n",
    "\n",
    "# Add the license type to the licenses table\n",
    "dfs['licenses'] = pd.merge(dfs['licenses'],license_types_from_classifications,left_on='_pkLicenseID',right_on='_fkLicenseID',how='left')\n",
    "\n",
    "# Clean up column names to clarify the source of the license type info\n",
    "dfs['licenses'] = dfs['licenses'].rename(columns={'LicenseType_x':'LicenseType_numeric','LicenseType_y':'LicenseType_from_classifications'})\n",
    "\n",
    "# First try using the type listed from the Classification table\n",
    "dfs['licenses']['LicenseTypeDescription'] = dfs['licenses']['LicenseType_from_classifications']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next try the alpha code from end of internal ODA license number\n",
    "\n",
    "# First pull the last few characters of the license number, which in recent years ODA has used to indicate type\n",
    "dfs['licenses']['Type_alphacode'] = dfs['licenses'].LicenseNumber.str.extract(r'[0-9]([A-Z]*)$')\n",
    "\n",
    "# Then pull list of types\n",
    "license_types_from_alpha = pd.read_csv('license-types-from-alpha.csv')\n",
    "license_types_from_alpha = license_types_from_alpha.rename(columns={'Description':'LicenseType_from_alpha'})\n",
    "\n",
    "# Eliminate superflous columns\n",
    "license_types_from_alpha.drop([col for col in license_types_from_alpha.columns if 'Unnamed' in col],axis=1,inplace=True)\n",
    "\n",
    "# Join them based on the license number code\n",
    "dfs['licenses'] = pd.merge(dfs['licenses'],license_types_from_alpha,left_on='Type_alphacode',right_on='Alpha_code',how='left')\n",
    "\n",
    "# If the classifications table didn't have the description we needed, used the one based on alpha code\n",
    "criteria = dfs['licenses'].LicenseTypeDescription.isnull()==True\n",
    "dfs['licenses'].loc[criteria,'LicenseTypeDescription'] = dfs['licenses'].LicenseType_from_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try joining based on the field LicenseType, which was used in early years but is no longer populated\n",
    "\n",
    "# Pull list of types using numeric code\n",
    "license_types_from_numeric = pd.read_csv('license-types-from-numeric.csv')\n",
    "license_types_from_numeric = license_types_from_numeric.rename(columns={'Description':'LicenseType_from_numeric'})\n",
    "\n",
    "# Eliminate superflous columns\n",
    "license_types_from_numeric.drop([col for col in license_types_from_numeric.columns if 'Unnamed' in col],axis=1,inplace=True)\n",
    "\n",
    "# Join the code description to the licenses table using the numeric code\n",
    "dfs['licenses'] = dfs['licenses'].merge(license_types_from_numeric[pd.notnull(license_types_from_numeric.Numeric_code)],left_on='LicenseType_numeric',right_on='Numeric_code',how='left')\n",
    "\n",
    "# If license type is still blank after other joins, use the version from numeric if available\n",
    "dfs['licenses'].loc[dfs['licenses'].LicenseTypeDescription.isnull() == True,'LicenseTypeDescription'] = dfs['licenses'].LicenseType_from_numeric\n",
    "\n",
    "# Fill nulls in License Types\n",
    "dfs['licenses'].LicenseTypeDescription = dfs['licenses'].LicenseTypeDescription.fillna('Not listed')\n",
    "\n",
    "# Created stripped-down license_ID dataframe with basic info\n",
    "license_IDs = dfs['licenses'][['_pkLicenseID','_fkLocationID','LicenseTypeDescription','LicenseStatusSecondary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate a set of only licenses that are active\n",
    "\n",
    "# Use the Secondary status, per Sarah's advice\n",
    "active_licenses = license_IDs[(license_IDs.LicenseStatusSecondary == 'Active')]\n",
    "\n",
    "# Create short list\n",
    "active_license_IDs = active_licenses[['_pkLicenseID','LicenseTypeDescription','_fkLocationID']]\n",
    "\n",
    "# Separate retail into new Dataframe\n",
    "active_retail_licenses = active_licenses[active_licenses.LicenseTypeDescription=='Retail Food Establishment']\n",
    "active_retail_license_IDs = active_retail_licenses[['_pkLicenseID','LicenseTypeDescription','_fkLocationID']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssuo1/OneDrive - Advance Local Media LLC/Code/food-safety/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Isolate physical addresses from the addresses table\n",
    "physical_addresses = dfs['addresses'][dfs['addresses'].AddressType.str.contains('hysical') == True]\n",
    "physical_addresses['gz_ModTimeStamp'] = pd.to_datetime(physical_addresses['gz_ModTimeStamp'], errors='coerce')\n",
    "physical_addresses = physical_addresses[physical_addresses['gz_ModTimeStamp'].isnull() == False]\n",
    "# If there are multiple physical addresses for a location, use the one updated most recently\n",
    "physical_addresses = physical_addresses.loc[physical_addresses.groupby('_fkLocationID').gz_ModTimeStamp.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Location processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX ISSUE WITH CURLY APOSTROPHE IN STORE NAME\n",
    "dfs['locations'].LocationName = dfs['locations'].LocationName.str.replace(u'\\u2019',\"'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate retail locations with one active license\n",
    "active_retail_location_IDs = active_retail_license_IDs.groupby('_fkLocationID').count().reset_index()\n",
    "active_retail_location_IDs = active_retail_location_IDs.drop(columns=['LicenseTypeDescription','_pkLicenseID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate locations that have specialized food processing along with a retail operation\n",
    "# First grab all licenses associated with a retail location\n",
    "active_all_licenses_retail_locations = pd.merge(active_license_IDs,active_retail_location_IDs,on='_fkLocationID',how='inner')\n",
    "location_licenses = active_all_licenses_retail_locations[['_fkLocationID','LicenseTypeDescription']]\n",
    "# Transpose license types into columns with 0-1 count for each column\n",
    "location_licenses = pd.pivot_table(location_licenses,index='_fkLocationID',columns='LicenseTypeDescription',aggfunc=len).rename_axis(None,axis=1).reset_index()\n",
    "location_licenses = location_licenses.fillna(0)\n",
    "# Flag locations that don't have at least a bakery or meat sellers license\n",
    "location_licenses['Bakery_or_meat'] = location_licenses['Bakery'] + location_licenses['Meat Sellers License']\n",
    "location_licenses['Bk_Ms_flag'] = 'No'\n",
    "location_licenses.loc[location_licenses['Bakery_or_meat'] > 0,'Bk_Ms_flag'] = 'Yes'\n",
    "# Add up columns that are specialty food processing license types\n",
    "#location_licenses['Processing_types']=location_licenses['Custom Meat Processor']+location_licenses['Custom Mobile Slaughter']+location_licenses['Custom Stationary Slaughter']+location_licenses['Dairy Products Plant']+location_licenses['Egg Handler']+location_licenses['Fluid Milk Producer']+location_licenses['Food Processing Establishment']+location_licenses['Milk Sampler-Grader']+location_licenses['Non-Processing Distributor Grade A']+location_licenses['Non-Slaughtering Processor']+location_licenses['Refrigerated Locker Plant']+location_licenses['Shellfish Distributor, Shipper, Wholesaler']+location_licenses['Shellfish Grower']+location_licenses['Shellfish Shucker/Packer']+location_licenses['Slaughterhouse']+location_licenses['Not listed']\n",
    "location_licenses['Processing_types']=location_licenses['Custom Meat Processor']+location_licenses['Custom Mobile Slaughter']+location_licenses['Custom Stationary Slaughter']+location_licenses['Dairy Products Plant']+location_licenses['Egg Handler']+location_licenses['Fluid Milk Producer']+location_licenses['Food Processing Establishment']+location_licenses['Milk Sampler-Grader']+location_licenses['Non-Processing Distributor Grade A']+location_licenses['Refrigerated Locker Plant']+location_licenses['Shellfish Distributor, Shipper, Wholesaler']+location_licenses['Shellfish Grower']+location_licenses['Shellfish Shucker/Packer']+location_licenses['Slaughterhouse']+location_licenses['Not listed']\n",
    "location_licenses['Processing_flag'] = 'No'\n",
    "location_licenses.loc[location_licenses['Processing_types'] > 0,'Processing_flag'] = 'Yes'\n",
    "location_licenses[['_fkLocationID','Processing_flag','Bk_Ms_flag']]\n",
    "# Add flags to retail locations frame indicating limitations on licenses at location\n",
    "active_retail_locations = pd.merge(dfs['locations'],location_licenses,left_on='_pkLocationID',right_on='_fkLocationID',how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flag locations that prepare raw food\n",
    "raw = dfs['classifications'][(dfs['classifications'].LicenseType=='Retail Food Establishment')&\n",
    "                       (dfs['classifications'].Classification1=='Packaged & Unpackaged Foods')&\n",
    "                       (dfs['classifications'].Classification2=='Raw/Precooked')]\n",
    "raw = raw.groupby(['_fkLicenseID']).ModifiedBy.count().reset_index()\n",
    "raw = raw.drop(columns='ModifiedBy')\n",
    "raw['Raw'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'raw' flag to the active retail license IDs\n",
    "active_retail_license_IDs_with_raw = pd.merge(active_retail_license_IDs,raw,left_on='_pkLicenseID',right_on='_fkLicenseID',how='left') ## If it's left join, then we end up with dupe\n",
    "active_retail_license_IDs_with_raw = active_retail_license_IDs_with_raw.drop(columns=['_pkLicenseID','LicenseTypeDescription','_fkLicenseID'])\n",
    "# Add this information to the retail locations list\n",
    "active_retail_locations = pd.merge(active_retail_locations,active_retail_license_IDs_with_raw,left_on='_pkLocationID',right_on='_fkLocationID',how='left')\n",
    "# Clean up\n",
    "active_retail_locations = active_retail_locations.drop(columns='_fkLocationID_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only raw food handling locations\n",
    "active_retail_locations=active_retail_locations[(active_retail_locations['FoodService'].str.contains('Full')==True)|\n",
    "                                                (active_retail_locations['Raw']=='Yes')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate places that also do food processing\n",
    "active_retail_locations=active_retail_locations[active_retail_locations['Processing_flag']=='No']\n",
    "# Strip it down to just an ID\n",
    "active_retail_location_IDs = active_retail_locations[['_pkLocationID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add physical addresses to active retail locations\n",
    "active_retail_locations = pd.merge(active_retail_locations,physical_addresses,left_on='_pkLocationID',right_on='_fkLocationID',how='left')\n",
    "active_retail_locations = active_retail_locations.drop(columns=['_fkLocationID_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from location name a chain name\n",
    "chains = { \"AFC Sushi\":[\"Afc Sushi\",\"AFC Sushi\"],\n",
    "          \"Hissho Sushi\":[\"Hissho\"],\n",
    "          \"Snowfox\":[\"Snowfox\"],\n",
    "          \"Little Samurais\":[\"Little Samurais\"],\n",
    "          \"Kikka Sushi\":[\"Kikka\",\"KIKKA\"],\n",
    "          \"FujiSan Sushi\":[\"FujiSan\",\"Fujisan\"],\n",
    "          \"Stop and Go\":[\"Stop and Go\",\"Stop And Go\",\"Stop & Go\",\"Stop N Go\",\"Stop n Go\"],\n",
    "          \"US Market\":[\"Us Market\",\"US Market\",\"U S Market\"],\n",
    "          \"Walmart\":[\"Wal-Mart\",\"Wal Mart\",\"Walmart\"],\n",
    "          \"WinCo\":[\"Winco\",\"WinCo\",\"Waremart\"],\n",
    "          \"Arco \":[\"Arco \",\"ARCO \",\"AM/PM\"],\n",
    "          \"TJ Maxx\":[\"T J Maxx\",\"TJ Maxx\",\"Tj Maxx\"],\n",
    "          \"TNT Market\":[\"T N T Market\",\"TNT Market\",\"Tnt Market\"],\n",
    "          \"Erickson's\":[\"Erickson's\",\"Ericksons\"],\n",
    "          \"Lil' Pantry\":[\"Lil Pantry\",\"Lil' Pantry\"],\n",
    "          \"Market of Choice\":[\"Market Of Choice\",\"Market of Choice\"],\n",
    "          \"McKay's Market\":[\"McKay's Market\",\"Mckay's Market\"],\n",
    "          \"7-Eleven\":[\"7-Eleven\",\"7 Eleven\"],\n",
    "          \"Bi-Mart\":[\"Bi Mart\",\"Bi-Mart\"],\n",
    "          \"Jackson's \":[\"Jacksons \",\"Jackson's \"],\n",
    "          \"Buy 2\":[\"Buy2\",\"Buy 2\"],\n",
    "          \"LTI/Milky Way\":[\"LTI/Milky Way\",\"LTI / Milky Way\"],\n",
    "          \"Reser's\":[\"Resers\",\"Reser's\"],\n",
    "          \"Franz Bakery\":[\"Franz Bakery\",\"Franz Family\"],\n",
    "          \"Market of Choice\":[\"Market of Choice\",\"Market Of Choice\"],\n",
    "          \"Marshall's\":[\"Marshall's #\",\"Marshalls #\"],\n",
    "          \"Everyone's Market\":[\"Everyone's Market\",\"Everyones Market\"],\n",
    "          \"A-1 Market\":[\"A-1 Market\",\"A1 Market\"],\n",
    "          \"Sportsman's Warehouse\":[\"Sportsman's Warehouse\",\"Sportsmans Warehouse\"],\n",
    "          \"Kmart\":[\"K Mart\",\"Kmart\"],\n",
    "          \"Tillamook County Creamery Association\":[\"Tillamook County Creamery\",\"Tillamook Co Creamery\"],\n",
    "          \"Hi School Pharmacy\":[\"Hi School\",\"Hi-School\"],\n",
    "          \"Loves Travel Stop\":[\"Loves Travel\",\"Love's Travel\"],\n",
    "          \"Swire Coca Cola\":[\"Swire Coca Cola\",\"Swire Coca-Cola\"],\n",
    "          \"H Mart\":[\"H Mart\",\"H-Mart\"],\n",
    "          \"Harry's Fresh Foods\":[\"Harry's Fresh Foods\",\"Harrys Fresh Foods\"],\n",
    "          \"Zupan's\":[\"Zupan's\",\"Zupans\"],\n",
    "          \"A-1 Market\":[\"A-1 Market\"],\n",
    "          \"Albertson's\":[\"Albertson\"],\n",
    "          \"Circle K\":[\"Circle K\"],\n",
    "          \"Costco\":[\"Costco\"],\n",
    "          \"Fred Meyer\":[\"Fred Meyer\"],\n",
    "          \"Little Samurai\":[\"Little Samurai\"],\n",
    "          \"New Seasons\":[\"New Seasons\"],\n",
    "          \"Ray's Food Place\":[\"Ray's Food Place\"],\n",
    "          \"Roth's\":[\"Roth's\"],\n",
    "          \"Safeway\":[\"Safeway\"],\n",
    "          \"Trader Joe's\":[\"Trader Joe\"],\n",
    "          \"Whole Foods\":[\"Whole Foods\"],\n",
    "          \"Papa Murphy's\":[\"Papa Murphy\"],\n",
    "          \"Plaid Pantry\":[\"Plaid Pant\"],\n",
    "          \"Chevron\":[\"Chevron\"],\n",
    "          \"Dollar Tree\":[\"Dollar Tree\",\"AM/PM\"],\n",
    "          \"Schwan\":[\"Schwan\"],\n",
    "          \"Walgreens\":[\"Walgreen\"],\n",
    "          \"Rite Aid\":[\"Rite Aid\"],\n",
    "          \"Dollar General\":[\"Dollar General\"],\n",
    "          \"Grocery Outlet\":[\"Grocery Outlet\"],\n",
    "          \"Dari Mart\":[\"Dari Mart\"],\n",
    "          \"Davis Tran-Lite\":[\"Davis Trans\"],\n",
    "          \"Hood River Juice\":[\"Hood River Juice\"],\n",
    "          \"Ross Dress for Less\":[\"Ross Dress\"],\n",
    "          \"General Nutrition\":[\"General Nutrition\"],\n",
    "          \"Center Market\":[\"Center Market\"],\n",
    "          \"Figaro's\":[\"Figaro\"],\n",
    "          \"Frito Lay\":[\"Frito Lay\"],\n",
    "          \"Home Depot\":[\"Home Depot\"],\n",
    "          \"Target\":[\"Target\"],\n",
    "          \"Cash & Carry\":[\"Cash & Carry\"],\n",
    "          \"La Mota\":[\"La Mota\"],\n",
    "          \"New Seasons\":[\"New Seasons\"],\n",
    "          \"Mr. Nice Guy\":[\"Nice Guy\"],\n",
    "          \"Zwald Transport\":[\"Zwald Transport\"],\n",
    "          \"Big Lots\":[\"Big Lots\"],\n",
    "          \"Hickory Farms\":[\"Hickory Farm\"],\n",
    "          \"Office Depot\":[\"Office Depot\"],\n",
    "          \"Stop N Save\":[\"Stop N Save\"],\n",
    "          \"24 Hour Fitness\":[\"24 Hour Fitness\"],\n",
    "          \"Natural Grocers\":[\"Natural Grocers\"],\n",
    "          \"Space Age\":[\"Space Age\"],\n",
    "          \"Big 5 Sporting Goods\":[\"Big 5\"],\n",
    "          \"Great Harvest\":[\"Great Harvest\"],\n",
    "          \"Staples\":[\"Staples\"],\n",
    "          \"Bed Bath and Beyond\":[\"Bed Bath\"],\n",
    "          \"Bimbo Bakeries USA\":[\"Bimbo\"],\n",
    "          \"Made In Oregon\":[\"Made In Oregon\"],\n",
    "          \"Minute Market\":[\"Minute Market\"],\n",
    "          \"Roth's\":[\"Roth's\"],\n",
    "          \"Tuesday Morning\":[\"Tuesday Morning\"],\n",
    "          \"Columbia Distributing\":[\"Columbia Distributing\"],\n",
    "          \"JC Penney\":[\"Jc Penney\"],\n",
    "          \"Western Beverage\":[\"Western Beverage\"],\n",
    "          \"Astro\":[\"Astro\"],\n",
    "          \"Crown Market\":[\"Crown Market\"],\n",
    "          \"Franz Thrift Store\":[\"Franz Thrift\"],\n",
    "          \"Old Navy\":[\"Old Navy\"],\n",
    "          \"See's Candies\":[\"See's\"],\n",
    "          \"Main Street Market\":[\"Main Street Market\"],\n",
    "          \"Speedy Mart\":[\"Speedy Mart\"],\n",
    "          \"American Market\":[\"American Market\"],\n",
    "          \"Cost Plus\":[\"Cost Plus\"],\n",
    "          \"DS Services\":[\"DS Services\"],\n",
    "          \"Electric Lettuce\":[\"Electric Lettuce\"],\n",
    "          \"Henningsen Cold Storage\":[\"Henningsen\"],\n",
    "          \"Sherm's Thunderbird\":[\"Sherm's\"],\n",
    "          \"Vitamin Shoppe\":[\"Vitamin Shoppe\"],\n",
    "          \"Williams Bakery\":[\"Williams Bakery\"],\n",
    "          \"Americold\":[\"Americold\"],\n",
    "          \"Attis Trading\":[\"Attis Trading\"],\n",
    "          \"Edible Arrangements\":[\"Edible Arrangements\"],\n",
    "          \"Fast Mart\":[\"Fast Mart\"],\n",
    "          \"Oregon Bud Company\":[\"Oregon Bud\"],\n",
    "          \"Pacific Seafood\":[\"Pacific Seafood\"],\n",
    "          \"Paradies\":[\"Paradies\"],\n",
    "          \"Short Stop\":[\"Short Stop\"],\n",
    "          \"Sweet Relief\":[\"Sweet Relief\"],\n",
    "          \"Umpqua Dairy\":[\"Umpqua Dair\"],\n",
    "          \"Weight Watchers\":[\"Weight Watchers\"],\n",
    "          \"Cannabis Nation\":[\"Cannabis Nation\"],\n",
    "          \"Cash King\":[\"Cash King\"],\n",
    "          \"Chalice Farms\":[\"Chalice Farms\"],\n",
    "          \"Euphoria Chocolate\":[\"Euphoria Chocolate\"],\n",
    "          \"Farmer Brothers\":[\"Farmer Brothers\"],\n",
    "          \"Going Green\":[\"Going Green\"],\n",
    "          \"Grocery Depot\":[\"Grocery Depot\"],\n",
    "          \"Harry And David\":[\"Harry And David\"],\n",
    "          \"Kaya Shack\":[\"Kaya Shack\"],\n",
    "          \"Merritt #1\":[\"Merritt #1\"],\n",
    "          \"Nake Windery\":[\"Nake Windery\"],\n",
    "          \"OG Collective\":[\"OG Collective\"],\n",
    "          \"Quality Food Center\":[\"Quality Food Center\"],\n",
    "          \"Rocky Mountain Chocolate\":[\"Rocky Mountain Chocolate\"],\n",
    "          \"Rogue Creamery\":[\"Rogue Creamery\"],\n",
    "          \"Today's Herbal Choice\":[\"Today's Herbal Choice\"],\n",
    "          \"Toys R Us\":[\"Toys R Us\"],\n",
    "          \"Ama Mini Mart\":[\"Ama Mini Mart\"],\n",
    "          \"Bridgeport Distributing\":[\"Bridgeport Distributing\"],\n",
    "          \"CBD Hemp\":[\"CBD Hemp\"],\n",
    "          \"Columbia River Dairy\":[\"Columbia River Dairy\"],\n",
    "          \"Colvin Oil\":[\"Colvin Oil\"],\n",
    "          \"Complete Nutrition\":[\"Complete Nutrition\"],\n",
    "          \"Dayton Natural Meats\":[\"Dayton Natural Meats\"],\n",
    "          \"Desert Lake Technologies\":[\"Desert Lake Technologies\"],\n",
    "          \"Everyday Deals\":[\"Everyday Deals\"],\n",
    "          \"Green Knottz\":[\"Green Knottz\"],\n",
    "          \"Green Zebra\":[\"Green Zebra\"],\n",
    "          \"Hood River Distillers\":[\"Hood River Distillers\"],\n",
    "          \"Humm Kombucha\":[\"Humm Kombucha\"],\n",
    "          \"Jenny Craig\":[\"Jenny Craig\"],\n",
    "          \"Joann Fabric\":[\"Joann Fabric\"],\n",
    "          \"Klamath Algae Products\":[\"Klamath Algae\"],\n",
    "          \"Macy's\":[\"Macy's\"],\n",
    "          \"Market Place Fresh Foods\":[\"Market Place Fresh Food\"],\n",
    "          \"Meduri Farms\":[\"Meduri Farm\"],\n",
    "          \"Moo Lines Inc\":[\"Moo Lines Inc\"],\n",
    "          \"Moonstruck Chocolate\":[\"Moonstruck Chocolate\"],\n",
    "          \"Mountain Rose Herbs\":[\"Mountain Rose Herbs\"],\n",
    "          \"Norpac Foods\":[\"Norpac Foods\"],\n",
    "          \"Nothing Bundt Cake\":[\"Nothing Bundt Cake\"],\n",
    "          \"Oakshire Brewing\":[\"Oakshire Brewing\"],\n",
    "          \"OFD Foods\":[\"OFD Foods\"],\n",
    "          \"One Stop Mart\":[\"One Stop Mart\"],\n",
    "          \"Oregon Cherry Growers\":[\"Oregon Cherry Growers\"],\n",
    "          \"Point Blank Distributing\":[\"Point Blank Distributing\"],\n",
    "          \"Portland Farmers Market\":[\"Portland Farmers Market\"],\n",
    "          \"Quick Stop Market\":[\"Quick Stop Market\"],\n",
    "          \"Rogue Valley Cannabis\":[\"Rogue Valley Cannabis\"],\n",
    "          \"Savy's Sweets\":[\"Savy's Sweets\"],\n",
    "          \"Schwietert's Cones and Candy\":[\"Schwietert\"],\n",
    "          \"Smart Choice Market\":[\"Smart Choice Market\"],\n",
    "          \"Spring Valley Dairy\":[\"Spring Valley Dairy\"],\n",
    "          \"Stop N Shop\":[\"Stop N Shop\"],\n",
    "          \"Summit Foods\":[\"Summit Foods\"],\n",
    "          \"Sunrise Market\":[\"Sunrise Market\"],\n",
    "          \"Super Supplements\":[\"Super Supplements\"],\n",
    "          \"Sur La Table\":[\"Sur La Table\"],\n",
    "          \"Tea Chai Te\":[\"Tea Chai Te\"],\n",
    "          \"The Fit Foods\":[\"The Fit Foods\"],\n",
    "          \"Tobacco Town\":[\"Tobacco Town\"],\n",
    "          \"Tokyo Starfish\":[\"Tokyo Starfish\"],\n",
    "          \"Tri Valley Food Mart\":[\"Tri Valley Food Mart\"],\n",
    "          \"United Market\":[\"United Market\"],\n",
    "          \"Vitamin World\":[\"Vitamin World\"],\n",
    "          \"Western Oregon Dispensary\":[\"Western Oregon Dispensary\"],\n",
    "          \"Wheeler Dealer\":[\"Wheeler Dealer\"],\n",
    "          \"Willamette Beverage\":[\"Willamette Beverage\"],\n",
    "          \"Wymore Transfer Company\":[\"Wymore Transfer Company\"]}\n",
    "import re\n",
    "for chain,variants in chains.iteritems():\n",
    "    for variant in variants:\n",
    "        my_regex = r\"(.*\" + re.escape(variant) + r\")\"\n",
    "        criteria = active_retail_locations.LocationName.str.match(my_regex)==True\n",
    "        active_retail_locations.loc[criteria,'Chain'] = chain\n",
    "\n",
    "# Different way of submitting literal regex to the search for chain names\n",
    "specials = { \"REI\":[\"^Rei$\",\"^Rei \",\"Recreational Equipment\"],\n",
    "            \"76\":[\"^76\",\"76 \"],\n",
    "            \"Ars Fresno\":[\"^Ars \"],\n",
    "            \"Home Goods\":[\"^Home Goods \"],\n",
    "            \"Neighborhood Market\":[\"^Neighborhood Market\"]\n",
    "           }\n",
    "for chain,variants in specials.iteritems():\n",
    "    for variant in variants:\n",
    "        my_regex = r\"(\" + variant + r\")\"\n",
    "        criteria = active_retail_locations.LocationName.str.match(my_regex)==True\n",
    "        active_retail_locations.loc[criteria,'Chain'] = chain\n",
    "\n",
    "# Special way of submitting regex to exclude certain words\n",
    "nots = {\"Shell\":[\"Shellfish\"],\"Nectar\":[\"Pure Nectar\",\"Nectar Creek\"]}\n",
    "for chain,variants in nots.iteritems():\n",
    "    for variant in variants:\n",
    "        my_regex = r\"(\" + re.escape(chain) + r\")\" + r\"(?!\" + variant + r\")\"\n",
    "        criteria = active_retail_locations.LocationName.str.match(my_regex)==True\n",
    "        active_retail_locations.loc[criteria,'Chain'] = chain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ssuo1/OneDrive - Advance Local Media LLC/Code/food-safety/ENV/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Isolate only completed inspections with a date listed\n",
    "dfs['inspections'].ContactDate = pd.to_datetime(dfs['inspections'].ContactDate, errors='coerce')\n",
    "dfs['inspections'] = dfs['inspections'][dfs['inspections'].ContactDate.isnull() == False]\n",
    "dfs['inspections'] = dfs['inspections'][dfs['inspections'].IsComplete == 1]\n",
    "\n",
    "# Isolate only routine inspections\n",
    "routine_inspections = dfs['inspections'][dfs['inspections'].ContactType == 'Routine']\n",
    "\n",
    "# Isolate only the latest\n",
    "latest_routine_inspections = routine_inspections.loc[routine_inspections.groupby('_fkLicenseID').ContactDate.idxmax()]\n",
    "latest_routine_inspection_IDs = latest_routine_inspections[['_pkContactID','_fkLicenseID']]\n",
    "latest_routine_inspection_IDs['Latest'] = 'Yes'\n",
    "\n",
    "# Add flag to all inspection records to show whether it's the latest\n",
    "dfs['inspections'] = pd.merge(dfs['inspections'],latest_routine_inspection_IDs,on=['_pkContactID','_fkLicenseID'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add information about the license type associated with the inspection\n",
    "dfs['inspections'] = pd.merge(dfs['inspections'],license_IDs,left_on='_fkLicenseID',right_on='_pkLicenseID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no license type is available, then borrow from \"contact type\" to populate license type. \n",
    "dfs['inspections'].loc[dfs['inspections'].LicenseTypeDescription.isnull()==True,'LicenseTypeDescription'] = dfs['inspections'].ContactType\n",
    "dfs['inspections'].loc[dfs['inspections'].LicenseTypeDescription=='Not listed','LicenseTypeDescription'] = dfs['inspections'].ContactType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate only inspections for active licenses\n",
    "active_all_licenses_retail_locations = pd.merge(active_license_IDs,active_retail_location_IDs,left_on='_fkLocationID',right_on='_pkLocationID',how='inner')\n",
    "active_all_licenses_retail_locations = active_all_licenses_retail_locations[['_pkLicenseID']]\n",
    "active_retail_inspections = pd.merge(active_all_licenses_retail_locations,dfs['inspections'],left_on='_pkLicenseID',right_on='_fkLicenseID',how='inner')\n",
    "active_retail_inspection_IDs = active_retail_inspections[['_pkContactID','_fkLocationID_x','_fkLicenseID',\"LicenseTypeDescription\"]]\n",
    "active_retail_inspection_IDs = active_retail_inspection_IDs.rename(columns={'_fkLocationID_x':'_fkLocationID'})\n",
    "\n",
    "active_latest_retail_inspections = active_retail_inspections[active_retail_inspections.Latest == 'Yes']\n",
    "active_latest_retail_inspections = active_latest_retail_inspections[active_latest_retail_inspections.LicenseStatusSecondary == 'Active']\n",
    "active_latest_retail_inspection_IDs = active_latest_retail_inspections[['_pkContactID','_fkLocationID_x','_pkLicenseID_x',\"LicenseTypeDescription\"]]\n",
    "active_latest_retail_inspection_IDs = active_latest_retail_inspection_IDs.rename(columns={'_fkLocationID_x':'_fkLocationID','_pkLicenseID_x':'_pkLicenseID'})\n",
    "\n",
    "# Per Sarah's advice, dropping prepackaged meat sellers because their violations are noted in RFE inspection\n",
    "active_latest_retail_inspection_IDs = active_latest_retail_inspection_IDs[(active_latest_retail_inspection_IDs.LicenseTypeDescription!='Pre-packaged only- Meat sellers')&(active_latest_retail_inspection_IDs.LicenseTypeDescription!='Prepackaged Meat Sellers')]\n",
    "# Same with full inspections table\n",
    "active_retail_inspections = active_retail_inspections[(active_retail_inspections.LicenseTypeDescription!='Pre-packaged only- Meat sellers')&(active_retail_inspections.LicenseTypeDescription!='Prepackaged Meat Sellers')]\n",
    "\n",
    "# Keep only the inspection ID\n",
    "active_latest_retail_inspection_IDs = active_latest_retail_inspections[['_pkContactID']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute data on violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the points field be a number\n",
    "dfs['violations'].Points = pd.to_numeric(dfs['violations'].Points, errors='coerce')\n",
    "# Add flag for high risk violations: 5-point violations with a Risk Factor\n",
    "criteria = (dfs['violations'].Points == 5) & (dfs['violations'].RiskFactor.isnull() == False) & (dfs['violations'].RiskFactor.str.match(r'^\\\\n$')==False)\n",
    "dfs['violations'].loc[criteria,'HighRisk'] = 'Yes'\n",
    "# Clean the Repeat field, converting '0 1' to 1 | checking with Sarah on this\n",
    "criteria = dfs['violations'].Repeat == '0 1'\n",
    "dfs['violations'].loc[criteria,'Repeat'] = '1'\n",
    "# Convert Repeat nulls to 0\n",
    "criteria = dfs['violations'].Repeat.isnull()==True\n",
    "dfs['violations'].loc[criteria,'Repeat'] = 0\n",
    "# Make Repeat field a number\n",
    "dfs['violations'].Repeat = pd.to_numeric(dfs['violations'].Repeat, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Fix the point values on retail locations that are active\n",
    "###############################################################\n",
    "\n",
    "# First, isolate violations found at active retail locations\n",
    "license_IDs_for_active_retail_locations = pd.merge(license_IDs,active_retail_location_IDs,left_on='_fkLocationID',right_on='_pkLocationID',how='right')\n",
    "license_IDs_for_active_retail_locations = license_IDs_for_active_retail_locations[license_IDs_for_active_retail_locations.LicenseStatusSecondary=='Active']\n",
    "license_IDs_for_active_retail_locations = license_IDs_for_active_retail_locations[['_pkLicenseID','_fkLocationID']]\n",
    "active_retail_violations = pd.merge(dfs['violations'],license_IDs_for_active_retail_locations,left_on='_fkLicenseID',right_on='_pkLicenseID',how='right')\n",
    "# Now store the original value in a different column name\n",
    "active_retail_violations = active_retail_violations.rename(columns={'Points':'Original_point_values'})\n",
    "active_retail_violations['Points'] = ''\n",
    "active_retail_violations.Points = pd.to_numeric(active_retail_violations.Points, errors='coerce')\n",
    "# Finally, update the point values based on Criticality Code, which is a consistent identifier when applied to retail \n",
    "criteria = active_retail_violations.CriticalityCode == 'C'\n",
    "active_retail_violations.loc[criteria,'Points'] = 0\n",
    "criteria = active_retail_violations.CriticalityCode == 'Pf'\n",
    "active_retail_violations.loc[criteria,'Points'] = 3\n",
    "criteria = active_retail_violations.CriticalityCode == 'P'\n",
    "active_retail_violations.loc[criteria,'Points'] = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To allow for inspections that found 0 violations, join violations with all inspections\n",
    "#active_retail_violations = pd.merge(active_retail_inspections,active_retail_violations,left_on='_pkContactID',right_on='_fkContactID',how='left')\n",
    "active_retail_violations = pd.merge(active_retail_inspection_IDs,active_retail_violations,left_on='_pkContactID',right_on='_fkContactID',how='left')\n",
    "\n",
    "# Convert null points to 0 points\n",
    "active_retail_violations.loc[active_retail_violations['_fkViolationID'].isnull()==True,'Points'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_retail_violations.drop([col for col in active_retail_violations.columns if '_y' in col],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_retail_violations = active_retail_violations.rename(columns= {'_fkLocationID_x':'_fkLocationID','_fkLicenseID_x':'_fkLicenseID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate violations found in LATEST inspections on active license\n",
    "active_latest_retail_violations = pd.merge(active_latest_retail_inspection_IDs,active_retail_violations,left_on='_pkContactID',right_on='_fkContactID',how='inner')\n",
    "\n",
    "# Isolate high-risk violations found in latest inspections on active license\n",
    "active_latest_risky_retail_violations = active_latest_retail_violations[active_latest_retail_violations['HighRisk']=='Yes']\n",
    "\n",
    "# Clean up column names\n",
    "active_latest_retail_violations.drop([col for col in active_latest_retail_violations.columns if '_y' in col],axis=1,inplace=True)\n",
    "active_latest_retail_violations = active_latest_retail_violations.drop(columns=['_pkContactID_x'])\n",
    "active_latest_risky_retail_violations.drop([col for col in active_latest_risky_retail_violations.columns if '_y' in col],axis=1,inplace=True)\n",
    "active_latest_risky_retail_violations = active_latest_risky_retail_violations.drop(columns=['_pkContactID_x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabulate total points deducted in latest inspection(s) at each location\n",
    "active_latest_violation_total_points = active_latest_retail_violations.groupby('_fkLocationID').Points.sum().reset_index()\n",
    "active_latest_violation_total_points = active_latest_violation_total_points.rename(columns={'Points':'Latest_deductions'})\n",
    "\n",
    "# Tabulate average points deducted from license\n",
    "active_latest_violation_total_by_license = active_latest_retail_violations.groupby(['_fkLocationID','_fkLicenseID','LicenseTypeDescription']).Points.sum().reset_index()\n",
    "active_latest_violation_average_points = active_latest_violation_total_by_license.groupby(['_fkLocationID']).Points.mean().reset_index()\n",
    "active_latest_violation_average_points = active_latest_violation_average_points.rename(columns={'Points':'Latest_deductions_average'})\n",
    "\n",
    "# Tabulate total points deducted from RETAIL license in latest inspection(s) at each location\n",
    "active_latest_retail_violation_total_points = active_latest_violation_total_by_license[active_latest_violation_total_by_license['LicenseTypeDescription']=='Retail Food Establishment']\n",
    "active_latest_retail_violation_total_points = active_latest_retail_violation_total_points.rename(columns={'Points':'Latest_retail_deductions'})\n",
    "active_latest_retail_violation_total_points = active_latest_retail_violation_total_points[['_fkLocationID','Latest_retail_deductions']]\n",
    "\n",
    "# Tabulate total number of repeat violations in latest inspection(s) at each location\n",
    "active_latest_repeat_violation_counts = active_latest_retail_violations.groupby(['_fkLocationID']).Repeat.sum().reset_index()\n",
    "active_latest_repeat_violation_counts = active_latest_repeat_violation_counts.rename(columns={'Repeat':'Repeat_violations'})\n",
    "\n",
    "# Tabulate total number of high risk violations in latest inspection at each location\n",
    "active_latest_risky_violation_counts = active_latest_risky_retail_violations.groupby(['_fkLocationID'])._pkViolationID.count().reset_index()\n",
    "active_latest_risky_violation_counts = active_latest_risky_violation_counts.rename(columns={'_pkViolationID':'High_risk_violations'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join these data points onto location info for retail, active only\n",
    "facilities = pd.merge(active_retail_locations,active_latest_violation_total_points,left_on='_pkLocationID',right_on='_fkLocationID',how='left')\n",
    "facilities = pd.merge(facilities,active_latest_violation_average_points,left_on='_pkLocationID',right_on='_fkLocationID',how='left')\n",
    "facilities = pd.merge(facilities,active_latest_retail_violation_total_points,left_on='_pkLocationID',right_on='_fkLocationID',how='left')\n",
    "facilities = pd.merge(facilities,active_latest_repeat_violation_counts,left_on='_pkLocationID',right_on='_fkLocationID',how='left')\n",
    "facilities = pd.merge(facilities,active_latest_risky_violation_counts,left_on='_pkLocationID',right_on='_fkLocationID',how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final cleanup of facilities table\n",
    "facilities = facilities.drop(columns=['_fkLocationID_x','_fkLocationID_y','_fkL2KPersonID'])\n",
    "facilities.Latest_deductions = facilities.Latest_deductions.fillna(0)\n",
    "facilities.Repeat_violations = facilities.Repeat_violations.fillna(0)\n",
    "facilities.High_risk_violations = facilities.High_risk_violations.fillna(0)\n",
    "\n",
    "# Drop unneeded columns with licensing 0-1 flags\n",
    "facilities = facilities.drop(facilities.columns[44:65],axis=1)\n",
    "facilities = facilities.drop(columns=['Processing_types'])\n",
    "\n",
    "# Output facilities file for Dave\n",
    "facilities.to_csv('facilities.csv',header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output facilities file for Dave\n",
    "facilities.to_csv('facilities.csv',header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make remaining base files for Dave\n",
    "\n",
    "# Clean up inspections\n",
    "active_retail_inspections = active_retail_inspections.rename(columns={'_fkLocationID_x':'_fkLocationID','LicenseTypeDescription_x':'LicenseTypeDescription'})\n",
    "# Export\n",
    "active_retail_inspections.to_csv('inspections.csv',header=True,index=False,encoding='utf-8')\n",
    "\n",
    "# Clean up violations\n",
    "active_retail_violations = active_retail_violations[active_retail_violations._pkViolationID.isnull()==False]\n",
    "active_retail_violations = active_retail_violations.drop(columns=['_pkLicenseID','_fkLocationID'])\n",
    "# Export\n",
    "active_retail_violations.to_csv('violations.csv', encoding=\"utf-8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
